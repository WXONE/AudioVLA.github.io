<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation">
  <meta name="keywords" content="Vision-Language-Action Model, Robotic Manipulation, Audio Feedback">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="X1yXHaIgYwRqh2RBW2otNG1EeYV1Z-5UJGtTJ8rH7aI" />
  <title>Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <!-- 修正：把 h1 文本改回真正标题 -->
          <h1 class="title is-1 publication-title">
            Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation
          </h1>

<div class="is-size-5 publication-authors">
  <span class="author-block"><a href="https://github.com/WXONE">Xiangyi Wei</a><sup>1</sup>,</span>
  <span class="author-block"><a href="https://github.com/5048429">Haotian Zhang</a><sup>1</sup>,</span>
  <span class="author-block"><a href="https://github.com/ppplusss">Xinyi Cao</a><sup>1</sup>,</span>
  <span class="author-block"><a href="https://github.com/python-No2">Siyu Xie</a><sup>1</sup>,</span>
  <span class="author-block"><a href="https://iipl.fudan.edu.cn/70/e2/c45863a684258/page.htm">Weifeng Ge</a><sup>2</sup>,</span>
  <span class="author-block"><a href="http://ihpdep.github.io/">Yang Li</a><sup>1</sup>,</span>
  <span class="author-block"><a href="https://faculty.ecnu.edu.cn/_s16/wzb/main.psp">Changbo Wang</a><sup>1</sup></span>
</div>

<div class="is-size-5 publication-authors">
  <span class="author-block"><sup>1</sup>East China Normal University</span>
  <span class="author-block" style="margin-left: 1rem;"><sup>2</sup>Fudan University</span>
</div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Reviewing</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/user/" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://arxiv.org/user/" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://github.com/WXONE/AudioVLA.github.io" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" src="static/audioVLA_imgs/audioVLA.mp4" autoplay muted loop playsinline></video>
    </div>
  </div>
  <script>
    var video = document.getElementById('teaser');
    video.playbackRate = 1;
  </script>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The Vision-Language-Action models (VLA) have achieved significant advances in robotic manipulation recently.
            However, vision-only VLA models create fundamental limitations, particularly in perceiving interactive and manipulation dynamic processes.
            This paper proposes Audio-VLA, a multimodal manipulation policy that leverages contact audio to perceive contact events and dynamic process feedback.
            Audio-VLA overcomes the vision-only constraints of VLA models. Additionally, this paper introduces the Task Completion Rate (TCR) metric to systematically evaluate dynamic operational processes.
            Audio-VLA employs pre-trained DINOv2 and SigLIP as visual encoders, AudioCLIP as the audio encoder, and Llama2 as the large language model backbone.
            We apply LoRA fine-tuning to these pre-trained modules to achieve robust cross-modal understanding of both visual and acoustic inputs.
            A multimodal projection layer aligns features from different modalities into the same feature space.
            Moreover RLBench and LIBERO simulation environments are enhanced by adding collision-based audio generation to provide realistic sound feedback during object interactions.
            Since current robotic manipulation evaluations focus on final outcomes rather than providing systematic assessment of dynamic operational processes, the proposed TCR metric measures how well robots perceive dynamic processes during manipulation, creating a more comprehensive evaluation metric.
            Extensive experiments on LIBERO, RLBench, and two real-world tasks demonstrate Audio-VLA's superior performance over vision-only comparative methods, while the TCR metric effectively quantifies dynamic process perception capabilities.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
    </div>

    <!-- Overview -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <img src="static/audioVLA_imgs/figure2_01.jpg" alt="Overview" />
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Audio-Enhanced Simulation Environments</h2>
        <p>
          To train and evaluate our proposed Audio-VLA, we augment LIBERO and RLBench simulation environments with realistic acoustic feedback via integrating real-world audio recordings triggered through physics-based collision detection.
          Our approach systematically collects contact sounds from physical manipulation, for each simulated task, we identify target objects by material properties and dimensions, then perform equivalent manipulations on similar real-world objects while recording contact audio at 48kHz using gripper-mounted microphones.
          These recordings are organized into a structured library indexed by material pairs, interaction types, and force magnitudes.
          The collected audio recordings are organized into a structured library indexed by material pairs, interaction types, and force magnitudes.
          During simulation, two types of collision events are monitored, including direct gripper–object contacts and interactions between grasped objects and the environment.
          When a collision is detected, the participants, impact velocity, and force magnitude are identified.
          The identified collision parameters are then used to query the audio library and retrieve appropriate sound samples.
          The retrieved audio is dynamically modulated, with amplitude scaled by collision force, pitch shifted according to object size, and duration adjusted for continuous contacts.
        </p>

        <!-- 3x3 视频网格 - 改为和 audioVLA.mp4 一样的简单播放方式 -->
        <div class="video-section">
          <div class="video-grid">
            <!-- 使用简单的 video 标签，去掉复杂的声音控制 -->
            <video class="grid-video" autoplay muted loop playsinline>
              <source src="static/audioVLA_videos/simualtion1.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline>
              <source src="static/audioVLA_videos/simulation2.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline>
              <source src="static/audioVLA_videos/simulation3.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline>
              <source src="static/audioVLA_videos/simulation4.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline>
              <source src="static/audioVLA_videos/simulation5.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline>
              <source src="static/audioVLA_videos/simulation6.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline>
              <source src="static/audioVLA_videos/simulation7.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline>
              <source src="static/audioVLA_videos/simulation8.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline>
              <source src="static/audioVLA_videos/simulation9.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>

    <style>
      .video-grid {
        display: grid;
        grid-template-columns: repeat(3, 1fr);
        gap: 12px;
      }
      .grid-video {
        width: 100%;
        height: 100%;
        aspect-ratio: 16/9;
        object-fit: cover;
        border-radius: 8px;
        display: block;
      }
      @media (max-width: 1024px) {
        .video-grid { grid-template-columns: repeat(2, 1fr); }
      }
      @media (max-width: 640px) {
        .video-grid { grid-template-columns: 1fr; }
      }
    </style>

    <!-- 你的 Simulation 实验简述 + 网格 -->
    <h3 class="title is-4">Simulation Experiments Results</h3>
    <p>
      In standard settings, Audio-VLA achieves the highest success rates on LIBERO and RLBench, surpassing all baselines.
      The integration of acoustic perception effectively complements visual input, allowing precise recognition of contact events and improving decision-making in long-horizon and contact-intensive tasks.
      When lighting, color, and texture vary, Audio-VLA maintains stable performance with minimal degradation compared to vision-only models.
      Its use of domain-invariant acoustic cues enables consistent contact perception and task execution even under visual disturbances.
    </p>

    <div style="text-align:center; margin-top: 8px;">
      <img src="static/audioVLA_imgs/simulation_result.png" alt="Simulation Experiments" style="max-width:100%; height:auto; display:inline-block;" loading="lazy">
    </div>
    <br/>

    <div class="sim-result-block">
      <div class="sim-row">
        <div class="sim-row-title">Standard Environment</div>
        <div class="sim-grid">
          <!-- 改为简单播放方式 -->
          <video class="sim-video" autoplay muted loop playsinline>
            <source src="static/audioVLA_videos/simulation_result1.mp4" type="video/mp4">
          </video>
          <video class="sim-video" autoplay muted loop playsinline>
            <source src="static/audioVLA_videos/simulation_result2.mp4" type="video/mp4">
          </video>
          <video class="sim-video" autoplay muted loop playsinline>
            <source src="static/audioVLA_videos/simulation_result3.mp4" type="video/mp4">
          </video>
        </div>
      </div>

      <div class="sim-row" style="margin-top: 16px;">
        <div class="sim-row-title">Domain shift</div>
        <div class="sim-grid">
          <!-- 改为简单播放方式 -->
          <video class="sim-video" autoplay muted loop playsinline>
            <source src="static/audioVLA_videos/simulation_result4.mp4" type="video/mp4">
          </video>
          <video class="sim-video" autoplay muted loop playsinline>
            <source src="static/audioVLA_videos/simulation_result5.mp4" type="video/mp4">
          </video>
          <video class="sim-video" autoplay muted loop playsinline>
            <source src="static/audioVLA_videos/simulation_result6.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>

    <style>
      .sim-result-block { margin-top: 12px; }
      .sim-row-title {
        text-align: center;
        font-weight: 600;
        margin: 8px 0 10px;
      }
      .sim-grid {
        display: grid;
        grid-template-columns: repeat(3, 1fr);
        gap: 12px;
      }
      .sim-video {
        width: 100%;
        height: 100%;
        aspect-ratio: 16/9;
        object-fit: cover;
        border-radius: 8px;
        display: block;
      }
      @media (max-width: 1024px) {
        .sim-grid { grid-template-columns: repeat(2, 1fr); }
      }
      @media (max-width: 640px) {
        .sim-grid { grid-template-columns: 1fr; }
      }
    </style>

  </div>
</section>

<section class="section">
  <div class="container">
    <h3 class="title is-4">Real-world Experiments Results</h3>
    <p>
      Under seen conditions, Audio-VLA achieves up to threefold higher success and completion rates than vision-only baselines on EAWM and S5GO.
      By capturing acoustic cues of friction and depth-weight dynamics, it effectively handles contact-dependent transitions that visual models fail to perceive.
      When visual appearances change, Audio-VLA maintains stable task performance while vision-only methods collapse.
      The domain-invariant nature of contact audio preserves physical interaction cues, enabling consistent understanding and generalization across unseen environments.
    </p>

    <div style="text-align:center; margin-top: 8px;">
      <img src="static/audioVLA_imgs/real_result.png" alt="real-world Experiments" style="max-width:100%; height:auto; display:inline-block;">
    </div>

    <!-- 四行三列视频（见/未见环境 + 列标题） -->
    <div class="real-result-block" style="margin-top:14px;">
      <div class="col-headers" style="display:grid; grid-template-columns:repeat(3,1fr); gap:12px; margin-bottom:6px;">
        <div style="text-align:center; font-weight:600; font-size:0.95rem;">Audio-VLA (Ours)</div>
        <div style="text-align:center; font-weight:600; font-size:0.95rem;">OpenVLA-OFT</div>
        <div style="text-align:center; font-weight:600; font-size:0.95rem;">π0</div>
      </div>

      <div class="row-title" style="text-align:center; font-weight:600; margin:8px 0 10px;">seen environment</div>

      <div class="video-grid" style="display:grid; grid-template-columns:repeat(3,1fr); gap:12px;">
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld1.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld2.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld3.mp4" type="video/mp4">
        </video>
      </div>

      <div class="video-grid" style="display:grid; grid-template-columns:repeat(3,1fr); gap:12px; margin-top:12px;">
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld4.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld5.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld6.mp4" type="video/mp4">
        </video>
      </div>

      <div class="row-title" style="text-align:center; font-weight:600; margin:16px 0 10px;">unseen environment</div>

      <div class="video-grid" style="display:grid; grid-template-columns:repeat(3,1fr); gap:12px;">
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld7.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld8.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld9.mp4" type="video/mp4">
        </video>
      </div>

      <div class="video-grid" style="display:grid; grid-template-columns:repeat(3,1fr); gap:12px; margin-top:12px;">
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld10.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld11.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld12.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
  coming soon
</code></pre>
  </div>
</section>

</body>
</html>
<!-- 放在页面底部，确保视频节点已渲染后执行 -->
<script>
  // 1) 统一给所有 <video> 加控件
  const vids = Array.from(document.querySelectorAll('video'));
  vids.forEach(v => {
    v.setAttribute('controls', '');                         // 显示控件
    v.setAttribute('controlsList', 'nodownload');           // 可选：隐藏下载按钮
    v.setAttribute('playsinline', '');                      // 移动端内联播放
    // 自动播放策略：保留静音+自动播
    v.setAttribute('autoplay', '');
    v.setAttribute('muted', '');
    v.setAttribute('loop', '');
  });

  // 2) 首次用户交互后，尝试统一取消静音（受浏览器策略约束）
  let soundUnlocked = false;
  async function unlockSoundOnce() {
    if (soundUnlocked) return;
    soundUnlocked = true;
    for (const v of vids) {
      try {
        v.muted = false;               // 取消静音
        if (v.paused) await v.play();  // 如果被策略暂停，显式播放
      } catch (e) {
        // 某些环境仍可能需要用户逐个点按
        console.warn('Unmute/play failed:', e);
      }
    }
    window.removeEventListener('pointerdown', unlockSoundOnce, {capture:true});
  }
  window.addEventListener('pointerdown', unlockSoundOnce, {capture:true, once:true});
</script>
