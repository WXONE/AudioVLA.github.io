<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation">
  <meta name="keywords" content="Vision-Language-Action Model, Robotic Manipulation, Audio Feedback">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="X1yXHaIgYwRqh2RBW2otNG1EeYV1Z-5UJGtTJ8rH7aI" />
  <title>Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <!-- ä¿®æ­£ï¼šæŠŠ h1 æ–‡æœ¬æ”¹å›çœŸæ­£æ ‡é¢˜ -->
          <h1 class="title is-1 publication-title">
            Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation
          </h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://github.com/WXONE">Xiangyi Wei</a>,</span>
            <span class="author-block"><a href="https://github.com/5048429">Haotian Zhang</a>,</span>
            <span class="author-block"><a href="https://github.com/ppplusss">Xinyi Cao</a>,</span>
            <span class="author-block"><a href="https://github.com/python-No2">Siyu Xie</a>,</span>
            <span class="author-block"><a href="https://iipl.fudan.edu.cn/70/e2/c45863a684258/page.htm">Weifeng Ge</a>,</span>
            <span class="author-block"><a href="http://ihpdep.github.io/">Yang Li</a>,</span>
            <span class="author-block"><a href="https://faculty.ecnu.edu.cn/_s16/wzb/main.psp">Changbo Wang</a></span>
            <!-- ä¿®æ­£ï¼šåˆ é™¤è¿™é‡ŒåŸæœ¬å¤šä½™çš„ </span> -->
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">East China Normal University</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Reviewing</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/user/" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://arxiv.org/user/" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://github.com/WXONE/AudioVLA.github.io" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" src="static/audioVLA_imgs/audioVLA.mp4" autoplay muted loop playsinline></video>
    </div>
  </div>
  <script>
    var video = document.getElementById('teaser');
    video.playbackRate = 1;
  </script>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The Vision-Language-Action models (VLA) have achieved significant advances in robotic manipulation recently.
            However, vision-only VLA models create fundamental limitations, particularly in perceiving interactive and manipulation dynamic processes.
            This paper proposes Audio-VLA, a multimodal manipulation policy that leverages contact audio to perceive contact events and dynamic process feedback.
            Audio-VLA overcomes the vision-only constraints of VLA models. Additionally, this paper introduces the Task Completion Rate (TCR) metric to systematically evaluate dynamic operational processes.
            Audio-VLA employs pre-trained DINOv2 and SigLIP as visual encoders, AudioCLIP as the audio encoder, and Llama2 as the large language model backbone.
            We apply LoRA fine-tuning to these pre-trained modules to achieve robust cross-modal understanding of both visual and acoustic inputs.
            A multimodal projection layer aligns features from different modalities into the same feature space.
            Moreover RLBench and LIBERO simulation environments are enhanced by adding collision-based audio generation to provide realistic sound feedback during object interactions.
            Since current robotic manipulation evaluations focus on final outcomes rather than providing systematic assessment of dynamic operational processes, the proposed TCR metric measures how well robots perceive dynamic processes during manipulation, creating a more comprehensive evaluation metric.
            Extensive experiments on LIBERO, RLBench, and two real-world tasks demonstrate Audio-VLA's superior performance over vision-only comparative methods, while the TCR metric effectively quantifies dynamic process perception capabilities.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
    </div>

    <!-- Overview -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <img src="static/audioVLA_imgs/figure2_01.jpg" alt="Overview" />
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Audio-Enhanced Simulation Environments</h2>
        <p>
          To train and evaluate our proposed Audio-VLA, we augment LIBERO and RLBench simulation environments with realistic acoustic feedback via integrating real-world audio recordings triggered through physics-based collision detection.
          Our approach systematically collects contact sounds from physical manipulation, for each simulated task, we identify target objects by material properties and dimensions, then perform equivalent manipulations on similar real-world objects while recording contact audio at 48kHz using gripper-mounted microphones.
          These recordings are organized into a structured library indexed by material pairs, interaction types, and force magnitudes.
          The collected audio recordings are organized into a structured library indexed by material pairs, interaction types, and force magnitudes.
          During simulation, two types of collision events are monitored, including direct gripperâ€“object contacts and interactions between grasped objects and the environment.
          When a collision is detected, the participants, impact velocity, and force magnitude are identified.
          The identified collision parameters are then used to query the audio library and retrieve appropriate sound samples.
          The retrieved audio is dynamically modulated, with amplitude scaled by collision force, pitch shifted according to object size, and duration adjusted for continuous contacts.
        </p>

        <!-- 3x3 è§†é¢‘ç½‘æ ¼ -->
        <div class="video-section">
          <div class="sound-toggle has-text-centered" style="margin: 0.5rem 0 1rem;">
            <button id="enable-sound" class="button is-primary is-small">ğŸ”Š å¼€å¯å£°éŸ³</button>
          </div>

          <div class="video-grid">
            <!-- ä¿®æ­£ï¼šæ–‡ä»¶åæ‹¼å†™ simualtion1 -> simulation1 -->
            <video class="grid-video" autoplay muted loop playsinline preload="metadata">
              <source src="static/audioVLA_videos/simualtion1.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline preload="metadata">
              <source src="static/audioVLA_videos/simulation2.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline preload="metadata">
              <source src="static/audioVLA_videos/simulation3.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline preload="metadata">
              <source src="static/audioVLA_videos/simulation4.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline preload="metadata">
              <source src="static/audioVLA_videos/simulation5.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline preload="metadata">
              <source src="static/audioVLA_videos/simulation6.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline preload="metadata">
              <source src="static/audioVLA_videos/simulation7.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline preload="metadata">
              <source src="static/audioVLA_videos/simulation8.mp4" type="video/mp4">
            </video>
            <video class="grid-video" autoplay muted loop playsinline preload="metadata">
              <source src="static/audioVLA_videos/simulation9.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>

    <style>
      .video-grid {
        display: grid;
        grid-template-columns: repeat(3, 1fr);
        gap: 12px;
      }
      .grid-video {
        width: 100%;
        height: 100%;
        aspect-ratio: 16/9;
        object-fit: cover;
        border-radius: 8px;
        display: block;
      }
      @media (max-width: 1024px) {
        .video-grid { grid-template-columns: repeat(2, 1fr); }
      }
      @media (max-width: 640px) {
        .video-grid { grid-template-columns: 1fr; }
      }
    </style>

    <script>
      // å—æµè§ˆå™¨ç­–ç•¥é™åˆ¶ï¼šå¸¦å£°éŸ³çš„è‡ªåŠ¨æ’­æ”¾éœ€è¦ç”¨æˆ·äº¤äº’
      (function () {
        const videos = Array.from(document.querySelectorAll('.grid-video'));
        const btn = document.getElementById('enable-sound');
        let soundEnabled = false;

        async function enableSoundForAll() {
          if (soundEnabled) return;
          soundEnabled = true;
          if (btn) btn.classList.add('is-loading');
          await Promise.all(videos.map(async v => {
            try {
              v.muted = false;
              if (v.paused) await v.play();
            } catch (e) {
              console.warn('Play with sound failed for a video:', e);
            }
          }));
          if (btn) {
            btn.classList.remove('is-loading');
            btn.classList.add('is-success');
            btn.textContent = 'âœ… å·²å¼€å¯å£°éŸ³';
            btn.disabled = true;
          }
          window.removeEventListener('pointerdown', onFirstInteraction, { capture: true });
        }

        function onFirstInteraction() { enableSoundForAll(); }

        btn?.addEventListener('click', enableSoundForAll);
        window.addEventListener('pointerdown', onFirstInteraction, { capture: true, once: true });
      })();
    </script>

    <!-- ä½ çš„ Simulation å®éªŒç®€è¿° + ç½‘æ ¼ï¼ˆå·²åœ¨ä¸Šä¸€è½®æ•´ç†ï¼Œè¿™é‡Œå¯ä¿æŒä¸å˜ï¼‰ -->
    <h3 class="title is-4">Simulation Experiments Results</h3>
    <p>
      In standard settings, Audio-VLA achieves the highest success rates on LIBERO and RLBench, surpassing all baselines.
      The integration of acoustic perception effectively complements visual input, allowing precise recognition of contact events and improving decision-making in long-horizon and contact-intensive tasks.
      When lighting, color, and texture vary, Audio-VLA maintains stable performance with minimal degradation compared to vision-only models.
      Its use of domain-invariant acoustic cues enables consistent contact perception and task execution even under visual disturbances.
    </p>

    <div style="text-align:center; margin-top: 8px;">
      <img src="static/audioVLA_imgs/simulation_result.png" alt="Simulation Experiments" style="max-width:100%; height:auto; display:inline-block;" loading="lazy">
    </div>
    <br/>

    <div class="sim-result-block">
      <div class="sim-row">
        <div class="sim-row-title">Standard Environment</div>
        <div class="sim-grid">
          <video class="sim-video" autoplay muted loop playsinline preload="metadata">
            <source src="static/audioVLA_videos/simulation_result1.mp4" type="video/mp4">
          </video>
          <video class="sim-video" autoplay muted loop playsinline preload="metadata">
            <source src="static/audioVLA_videos/simulation_result2.mp4" type="video/mp4">
          </video>
          <video class="sim-video" autoplay muted loop playsinline preload="metadata">
            <source src="static/audioVLA_videos/simulation_result3.mp4" type="video/mp4">
          </video>
        </div>
      </div>

      <div class="sim-row" style="margin-top: 16px;">
        <div class="sim-row-title">Domain shift</div>
        <div class="sim-grid">
          <video class="sim-video" autoplay muted loop playsinline preload="metadata">
            <source src="static/audioVLA_videos/simulation_result4.mp4" type="video/mp4">
          </video>
          <video class="sim-video" autoplay muted loop playsinline preload="metadata">
            <source src="static/audioVLA_videos/simulation_result5.mp4" type="video/mp4">
          </video>
          <video class="sim-video" autoplay muted loop playsinline preload="metadata">
            <source src="static/audioVLA_videos/simulation_result6.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>

    <style>
      .sim-result-block { margin-top: 12px; }
      .sim-row-title {
        text-align: center;
        font-weight: 600;
        margin: 8px 0 10px;
      }
      .sim-grid {
        display: grid;
        grid-template-columns: repeat(3, 1fr);
        gap: 12px;
      }
      .sim-video {
        width: 100%;
        height: 100%;
        aspect-ratio: 16/9;
        object-fit: cover;
        border-radius: 8px;
        display: block;
      }
      @media (max-width: 1024px) {
        .sim-grid { grid-template-columns: repeat(2, 1fr); }
      }
      @media (max-width: 640px) {
        .sim-grid { grid-template-columns: 1fr; }
      }
    </style>

  </div>
</section>

<section class="section">
  <div class="container">
    <h3 class="title is-4">Real-world Experiments Results</h3>
    <p>
      Under seen conditions, Audio-VLA achieves up to threefold higher success and completion rates than vision-only baselines on EAWM and S5GO.
      By capturing acoustic cues of friction and depth-weight dynamics, it effectively handles contact-dependent transitions that visual models fail to perceive.
      When visual appearances change, Audio-VLA maintains stable task performance while vision-only methods collapse.
      The domain-invariant nature of contact audio preserves physical interaction cues, enabling consistent understanding and generalization across unseen environments.
    </p>

    <div style="text-align:center; margin-top: 8px;">
      <img src="static/audioVLA_imgs/real_result.png" alt="real-world Experiments" style="max-width:100%; height:auto; display:inline-block;">
    </div>

    <!-- å››è¡Œä¸‰åˆ—è§†é¢‘ï¼ˆè§/æœªè§ç¯å¢ƒ + åˆ—æ ‡é¢˜ï¼‰ -->
    <div class="real-result-block" style="margin-top:14px;">
      <div class="col-headers" style="display:grid; grid-template-columns:repeat(3,1fr); gap:12px; margin-bottom:6px;">
        <div style="text-align:center; font-weight:600; font-size:0.95rem;">Audio-VLA (Ours)</div>
        <div style="text-align:center; font-weight:600; font-size:0.95rem;">OpenVLA-OFT</div>
        <div style="text-align:center; font-weight:600; font-size:0.95rem;">Ï€0</div>
      </div>

      <div class="row-title" style="text-align:center; font-weight:600; margin:8px 0 10px;">seen environment</div>

      <div class="video-grid" style="display:grid; grid-template-columns:repeat(3,1fr); gap:12px;">
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld1.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld2.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld3.mp4" type="video/mp4">
        </video>
      </div>

      <div class="video-grid" style="display:grid; grid-template-columns:repeat(3,1fr); gap:12px; margin-top:12px;">
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld4.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld5.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld6.mp4" type="video/mp4">
        </video>
      </div>

      <div class="row-title" style="text-align:center; font-weight:600; margin:16px 0 10px;">unseen environment</div>

      <div class="video-grid" style="display:grid; grid-template-columns:repeat(3,1fr); gap:12px;">
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld7.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld8.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld9.mp4" type="video/mp4">
        </video>
      </div>

      <div class="video-grid" style="display:grid; grid-template-columns:repeat(3,1fr); gap:12px; margin-top:12px;">
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld10.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld11.mp4" type="video/mp4">
        </video>
        <video class="rw-video" autoplay muted loop playsinline preload="metadata" style="width:100%; aspect-ratio:9/16; object-fit:cover; border-radius:8px;">
          <source src="static/audioVLA_videos/realworld12.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
  coming soon
</code></pre>
  </div>
</section>

</body>
</html>
<!-- æ”¾åœ¨é¡µé¢åº•éƒ¨ï¼Œç¡®ä¿è§†é¢‘èŠ‚ç‚¹å·²æ¸²æŸ“åæ‰§è¡Œ -->
<script>
  // 1) ç»Ÿä¸€ç»™æ‰€æœ‰ <video> åŠ æ§ä»¶
  const vids = Array.from(document.querySelectorAll('video'));
  vids.forEach(v => {
    v.setAttribute('controls', '');                         // æ˜¾ç¤ºæ§ä»¶
    v.setAttribute('controlsList', 'nodownload');           // å¯é€‰ï¼šéšè—ä¸‹è½½æŒ‰é’®
    v.setAttribute('playsinline', '');                      // ç§»åŠ¨ç«¯å†…è”æ’­æ”¾
    // è‡ªåŠ¨æ’­æ”¾ç­–ç•¥ï¼šä¿ç•™é™éŸ³+è‡ªåŠ¨æ’­
    v.setAttribute('autoplay', '');
    v.setAttribute('muted', '');
    v.setAttribute('loop', '');
  });

  // 2) é¦–æ¬¡ç”¨æˆ·äº¤äº’åï¼Œå°è¯•ç»Ÿä¸€å–æ¶ˆé™éŸ³ï¼ˆå—æµè§ˆå™¨ç­–ç•¥çº¦æŸï¼‰
  let soundUnlocked = false;
  async function unlockSoundOnce() {
    if (soundUnlocked) return;
    soundUnlocked = true;
    for (const v of vids) {
      try {
        v.muted = false;               // å–æ¶ˆé™éŸ³
        if (v.paused) await v.play();  // å¦‚æœè¢«ç­–ç•¥æš‚åœï¼Œæ˜¾å¼æ’­æ”¾
      } catch (e) {
        // æŸäº›ç¯å¢ƒä»å¯èƒ½éœ€è¦ç”¨æˆ·é€ä¸ªç‚¹æŒ‰
        console.warn('Unmute/play failed:', e);
      }
    }
    window.removeEventListener('pointerdown', unlockSoundOnce, {capture:true});
  }
  window.addEventListener('pointerdown', unlockSoundOnce, {capture:true, once:true});
</script>
